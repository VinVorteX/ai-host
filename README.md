# ğŸ¤– Riva - NextGen AI Assistant

Riva is an intelligent voice-powered AI assistant with RAG (Retrieval-Augmented Generation), voice cloning, and ultra-low latency. Built for the NextGen Supercomputing Club.

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green.svg)
![React](https://img.shields.io/badge/React-18.2+-61dafb.svg)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20Linux%20%7C%20macOS-lightgrey)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## âœ¨ Features

- ğŸ¤ **Voice Interaction** - Speak naturally, get instant AI responses
- ğŸ§  **Smart FAQ System** - TF-IDF powered semantic matching with caching
- ğŸ—£ï¸ **Voice Cloning** - Clone any voice using ElevenLabs API
- âš¡ **Ultra-Low Latency** - Optimized pipeline with concurrent processing
- ğŸŒ **Cross-Platform** - Works on Windows, Linux, and macOS
- ğŸ¨ **JARVIS-Style UI** - Circular wave animations with React
- ğŸ”„ **Fallback Systems** - Multiple TTS/STT options for reliability
- ğŸš€ **FastAPI Backend** - High-performance async API

## ğŸ¯ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 16+ (for React frontend)
- OpenAI API key
- Microphone access

### Installation

```bash
# Clone repository
git clone <your-repo-url>
cd ai-host

# Create virtual environment
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate

# Install Python dependencies
pip install -r requirements.txt

# Install frontend dependencies
cd frontend && npm install && cd ..

# Setup environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY2
```

### Run Development Mode

```bash
# Start both backend and frontend
./start_dev.sh

# Frontend: http://localhost:3000
# Backend:  http://localhost:5000
# API Docs: http://localhost:5000/docs
```

### Run Production Mode

```bash
# Build React frontend
cd frontend && npm run build && cd ..

# Start FastAPI server
python start.py
# Open http://localhost:5000
```

## ğŸ¨ Web Interface

Modern React frontend with JARVIS-style animations:
- **âš›ï¸ React 18** with Hooks and modern patterns
- **âš¡ Vite** for lightning-fast development
- **ğŸ¯ JARVIS-style circular waves** - Blue (idle), Red (recording), Green (processing)
- **ğŸ’« Glowing "RIVA" text** in center
- **ğŸ¤ Voice recording** with visual feedback
- **ğŸ”Š Real-time streaming** responses
- **ğŸ“± Fully responsive** design

## ğŸ”§ Configuration

Edit `config.py` or `.env`:

```env
# Required
OPENAI_API_KEY2=your_openai_key

# Optional - Voice Cloning
ELEVENLABS_API_KEY=your_elevenlabs_key
ELEVENLABS_VOICE_ID=your_voice_id
USE_VOICE_CLONE=true

# Performance Tuning
RECORD_SECONDS=3
MAX_TOKENS=100
TEMPERATURE=0.2
```

## ğŸ—£ï¸ Voice Cloning Setup

```bash
# Interactive setup
python setup_voice_clone.py

# Or manually configure in .env
ELEVENLABS_API_KEY=your_key
ELEVENLABS_VOICE_ID=voice_id
USE_VOICE_CLONE=true
```

See [VOICE_CLONE_SETUP.md](VOICE_CLONE_SETUP.md) for details.

## ğŸ“ Project Structure

```
ai-host/
â”œâ”€â”€ ai/                 # AI & RAG logic
â”‚   â”œâ”€â”€ chat.py        # ChatGPT integration
â”‚   â””â”€â”€ knowledge.py   # FAQ system with TF-IDF
â”œâ”€â”€ audio/             # Audio processing
â”‚   â”œâ”€â”€ recorder.py    # Microphone recording
â”‚   â”œâ”€â”€ stt.py         # Speech-to-text
â”‚   â”œâ”€â”€ tts.py         # Text-to-speech
â”‚   â””â”€â”€ voice_clone.py # Voice cloning
â”œâ”€â”€ frontend/          # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx    # Main app with JARVIS UI
â”‚   â”‚   â””â”€â”€ styles/    # CSS files
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ utils/             # Utilities
â”‚   â””â”€â”€ audio_player.py # Cross-platform audio playback
â”œâ”€â”€ app.py            # FastAPI application
â”œâ”€â”€ start.py          # Production startup script
â”œâ”€â”€ start_dev.sh      # Development startup script
â””â”€â”€ config.py         # Configuration
```

## ğŸ¯ Usage

### Web Mode

1. Open browser to `http://localhost:3000` (dev) or `http://localhost:5000` (prod)
2. Click the center RIVA button
3. Speak your question
4. Get instant AI response with voice

### CLI Mode

```bash
python main.py

# Options:
# 1. Ask a question (voice)
# 2. Show FAQ stats
# 3. Exit
```

### API Mode

```python
from ai.chat import ask_chatgpt

response = ask_chatgpt("What is supercomputing?")
print(response)
```

## ğŸ”Š Audio Requirements

### Windows
- Built-in audio support âœ…

### macOS
- Built-in `afplay` âœ…

### Linux
Install audio players:
```bash
# Debian/Ubuntu
sudo apt install mpg123 ffmpeg alsa-utils

# Fedora/RHEL
sudo dnf install mpg123 ffmpeg alsa-utils

# Arch
sudo pacman -S mpg123 ffmpeg alsa-utils
```

## âš¡ Performance Optimizations

- **FastAPI** - 40-60% faster than Flask
- **3-second recording** for quick responses
- **gpt-4o-mini** for 3x faster responses
- **Connection pooling** for API calls
- **Concurrent processing** with ThreadPoolExecutor
- **FAQ caching** for instant repeated queries
- **Reduced token limits** for faster generation

## ğŸ› ï¸ Troubleshooting

### No audio playback
```bash
# Check available players
python -c "from utils.audio_player import check_audio_dependencies; check_audio_dependencies()"

# Install missing dependencies (Linux)
sudo apt install mpg123 ffmpeg
```

### Microphone not working
```bash
# Test recording
python -c "from audio.recorder import record_to_wav; record_to_wav('test.wav', 3)"
```

### API errors
- Verify API key in `.env`
- Check internet connection
- Ensure sufficient API credits

## ğŸ“Š FAQ System

The assistant uses TF-IDF semantic matching to find relevant FAQs before querying ChatGPT, reducing latency and API costs.

Add custom FAQs:
```python
from ai.chat import add_new_faq

add_new_faq(
    "What are office hours?",
    "Office hours are Monday-Friday, 2-4 PM in Room 301."
)
```

## ğŸš€ API Documentation

FastAPI provides automatic interactive API docs:
- **Swagger UI**: http://localhost:5000/docs
- **ReDoc**: http://localhost:5000/redoc

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

## ğŸ“ License

MIT License - see LICENSE file

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 and Whisper
- ElevenLabs for voice cloning
- FastAPI for high-performance backend
- React for modern frontend
- NextGen Supercomputing Club

## ğŸ“§ Support

- Email: nextgenclub@university.edu
- Twitter: @NextGenHPC
- Issues: GitHub Issues

---

**Built with â¤ï¸ by NextGen Supercomputing Club**
